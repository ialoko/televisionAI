{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ialoko/televisionAI/blob/main/Project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification Empirical Study of TV Shows on Netflix\n",
        "\n",
        "CSI4106 Project 1 Group 22\n",
        "\n",
        "\n",
        "\n",
        ">Iyiola Aloko\n",
        "\n",
        "\n",
        "\n",
        ">Emily Bonneville\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PA9i4e5U4sti"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvOYsVLWIGWb"
      },
      "source": [
        "#Perform a classification empirical study"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**1. Understanding the classification task for the dataset**\n",
        "\n",
        "a. This classification empirical study will use the \"Netflix Disney+ Prime Video Hulu Shows Collection\" dataset from Kaggle. It originally is a multi-class but we will only select one class which makes this study a binary classification\n",
        "\n",
        "b. The goal is to analyze information about TV shows and predict wether or not they are streaming on Netflix. The reason we chose this dataset is we did not want one that was very black-and-white but also not one that would have data that is too complicated since we only want to cover the basics of machine learning. We concluded that this dataset works well for this study because it is between those two extremes. The result assumptions of each TV show is something that even humans cannot know 100% if it is on Netflix or not.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gXkSkkBJp1d7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**2. Analyzing the dataset**\n",
        "\n",
        "*   Number of features: 6 (only analyzing 4)\n",
        "*   Missing data: a few missing for \"Age\" (40% of examples) and \"IMDB Rating\" (18% of examples) \n",
        "*   Number of training examples: 5368\n",
        "*   Number of classes: 4 (only using 1)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8f7tsinNrz2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**3. Feature engineering**\n",
        "\n",
        "All the necessary features are present. However, the 'ID' feature and 'Type' feature (value of 1 if is a TV show) seem useless in analyzing the dataset so these will not be considered in the study. As mentioned, we will only evaluate the data for the class 'Netflix', therefore the other classes will be removed.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SupjCX37smyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**4. Encoding the features**\n",
        "\n",
        "All of the features are discrete. The only data transformation that needs to be done is discretization bin-making for 'Rotten Tomatoes', 'IMDb' and 'Year'. For example, the values of 'Rotten Tomatoes' are originally strings from '0/100' to '100/100' but they will be converted to integer values representing 4 different bins (using integers allows the system to use discrete values).\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dLPpLZLRuoOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary modules:"
      ],
      "metadata": {
        "id": "wc2VQjwH0Kym"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_Pdj0MUDsJ-"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import seaborn as sns\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "#cross validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate  #used for cross validation\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# evaluate a logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#import Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Import Multilayer perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#Import for Precision/recall measures\n",
        "from sklearn.metrics import precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNWgQSfgGx9i"
      },
      "source": [
        "Importing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sXDcj1CGxY_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8685d9-7714-41b2-8c10-e29766d906f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['18+' '16+' '7+' 'all' nan '13+']\n",
            "[4 3 2 1 0]\n",
            "[3 2 1 0]\n",
            "[4 5 3 2 1 0]\n"
          ]
        }
      ],
      "source": [
        "from scipy.sparse import data\n",
        "\n",
        "# Importing Data\n",
        "#dataset = pd.read_csv('tv_shows.csv')\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/ebonn088/CSI4106-Project1/main/tv_shows.csv')\n",
        "# The id column is not relevant\n",
        "dataset.drop(columns=['Unnamed: 0'],inplace=True)\n",
        "dataset.drop(columns=['ID'],inplace=True)\n",
        "# The 'type' column is not relevant, as we already know the sets are all tv shows\n",
        "dataset.drop(columns=['Type'],inplace=True)\n",
        "\n",
        "#figure out the unique Age categories of  so we can encode them with numerical values\n",
        "print(dataset['Age'].unique())\n",
        "dataset['Age'] = dataset['Age'].replace(\n",
        "    ['18+', '16+', 'all','7+', '13+'],\n",
        "    [18, 16, 0, 7, 13])\n",
        "\n",
        "#Encode Imdb categories as numerical values\n",
        "dataset['IMDb'] = dataset['IMDb'].str.slice(0,3).astype(float) #converts strings like '9.5/10' to a value 9.5\n",
        "dataset['IMDb'] = np.digitize(dataset['IMDb'], [3,5,7,8])\n",
        "print(dataset['IMDb'].unique())\n",
        "\n",
        "#Encode Imdb categories as numerical values\n",
        "dataset['Rotten Tomatoes'] = dataset['Rotten Tomatoes'].str.slice(0,-4).astype(float) #converts strings like '95/100' to a value 95\n",
        "dataset['Rotten Tomatoes'] = np.digitize(dataset['Rotten Tomatoes'], [30,50,70])\n",
        "print(dataset['Rotten Tomatoes'].unique())\n",
        "\n",
        "#Encode Year category as numerical values\n",
        "dataset['Year'] = np.digitize(dataset['Year'], [1960,1980,2000,2005,2009])\n",
        "print(dataset['Year'].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Skew Age and IMDb so best to replace with mode or median"
      ],
      "metadata": {
        "id": "fsphuPnJP3JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(dataset['Age'])\n",
        "clear_output()  # clears console output"
      ],
      "metadata": {
        "id": "px9lPuZgF3DT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9bd1371b-44f9-4f9f-be67-e07bd29c0dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(dataset['IMDb'])\n",
        "clear_output()  # clears console output"
      ],
      "metadata": {
        "id": "FUSCM6I3F5xk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ef725db6-cad4-4173-c08e-87e2df5cddea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputing the missing values to avoid NaN loss later on\n",
        "#dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mode().iloc[0])\n",
        "dataset['Age'] = dataset['Age'].fillna(1)\n",
        "dataset['IMDb'] = dataset['IMDb'].fillna(dataset['IMDb'].mode().iloc[0])\n",
        "dataset[1:21] #first 20 rows "
      ],
      "metadata": {
        "id": "xSMVye8aF-_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "cf302766-5c22-45ac-abc8-24e78c651f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Title  Year   Age  IMDb  Rotten Tomatoes  Netflix  \\\n",
              "1              Stranger Things     5  16.0     4                3        1   \n",
              "2              Attack on Titan     5  18.0     4                3        1   \n",
              "3             Better Call Saul     5  18.0     4                3        1   \n",
              "4                         Dark     5  16.0     4                3        1   \n",
              "5   Avatar: The Last Airbender     4   7.0     4                3        1   \n",
              "6               Peaky Blinders     5  18.0     4                3        1   \n",
              "7             The Walking Dead     5  18.0     4                3        1   \n",
              "8                 Black Mirror     5  18.0     4                3        1   \n",
              "9           The Queen's Gambit     5  18.0     4                3        1   \n",
              "10                  Mindhunter     5  18.0     4                3        1   \n",
              "11                   Community     5   7.0     4                3        1   \n",
              "12                      Narcos     5  18.0     4                3        1   \n",
              "13                   Shameless     5  18.0     4                3        1   \n",
              "14                 Money Heist     5  18.0     4                3        1   \n",
              "15          Marvel's Daredevil     5  18.0     4                3        1   \n",
              "16                     Lucifer     5  16.0     4                3        1   \n",
              "17                Supernatural     4  16.0     4                3        1   \n",
              "18                 The Witcher     5  18.0     4                3        1   \n",
              "19                       Ozark     5  18.0     4                3        1   \n",
              "20                   The Crown     5  18.0     4                3        1   \n",
              "\n",
              "    Hulu  Prime Video  Disney+  \n",
              "1      0            0        0  \n",
              "2      1            0        0  \n",
              "3      0            0        0  \n",
              "4      0            0        0  \n",
              "5      0            1        0  \n",
              "6      0            0        0  \n",
              "7      0            0        0  \n",
              "8      0            0        0  \n",
              "9      0            0        0  \n",
              "10     0            0        0  \n",
              "11     1            1        0  \n",
              "12     0            0        0  \n",
              "13     1            1        0  \n",
              "14     0            0        0  \n",
              "15     0            0        0  \n",
              "16     0            0        0  \n",
              "17     0            0        0  \n",
              "18     0            0        0  \n",
              "19     0            0        0  \n",
              "20     0            0        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e2a99ae-c18d-47d0-83e7-7086c91ee4be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Age</th>\n",
              "      <th>IMDb</th>\n",
              "      <th>Rotten Tomatoes</th>\n",
              "      <th>Netflix</th>\n",
              "      <th>Hulu</th>\n",
              "      <th>Prime Video</th>\n",
              "      <th>Disney+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stranger Things</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attack on Titan</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Better Call Saul</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dark</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Avatar: The Last Airbender</td>\n",
              "      <td>4</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Peaky Blinders</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Walking Dead</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Black Mirror</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The Queen's Gambit</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mindhunter</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Community</td>\n",
              "      <td>5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Narcos</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shameless</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Money Heist</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Marvel's Daredevil</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Lucifer</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Supernatural</td>\n",
              "      <td>4</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>The Witcher</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Ozark</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>The Crown</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e2a99ae-c18d-47d0-83e7-7086c91ee4be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e2a99ae-c18d-47d0-83e7-7086c91ee4be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e2a99ae-c18d-47d0-83e7-7086c91ee4be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table 1"
      ],
      "metadata": {
        "id": "LeTw6f_45YUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###**5. Preparing the dataset for the experiment, using Cross-validation**\n",
        "\n",
        "The goal of cross-validation is to let us know which part of the training data we should use in order to get the highest accuracy when testing.\n",
        "\n",
        "We will be using K-Folds cross validation. \n",
        "\n",
        "We will split the dataset into 5 folds. Each fold is then used once as a validation while the k - 1 (4) remaining folds form the training set."
      ],
      "metadata": {
        "id": "Kt7D0nfU7xwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the cross-validation procedure\n",
        "# X should be features\n",
        "#y should be classes\n",
        "#X = dataset[['Year', 'Age', 'IMDb', 'Rotten Tomatoes', 'Hulu', 'Prime Video', 'Disney+']]\n",
        "X = dataset[['Year', 'Age', 'IMDb', 'Rotten Tomatoes']]\n",
        "y = dataset[['Netflix']]\n",
        "\n",
        "kf = KFold(n_splits=5) #selection 5 folds\n",
        "for train_index, test_index in kf.split(X):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
      ],
      "metadata": {
        "id": "exWiY3b4CacY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6412f8-ee8e-4063-daa3-d9edc46f527b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [1074 1075 1076 ... 5365 5366 5367] TEST: [   0    1    2 ... 1071 1072 1073]\n",
            "TRAIN: [   0    1    2 ... 5365 5366 5367] TEST: [1074 1075 1076 ... 2145 2146 2147]\n",
            "TRAIN: [   0    1    2 ... 5365 5366 5367] TEST: [2148 2149 2150 ... 3219 3220 3221]\n",
            "TRAIN: [   0    1    2 ... 5365 5366 5367] TEST: [3222 3223 3224 ... 4292 4293 4294]\n",
            "TRAIN: [   0    1    2 ... 4292 4293 4294] TEST: [4295 4296 4297 ... 5365 5366 5367]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we have the indices used to split X and y into the train and test sets using 5-fold cross validation. \n"
      ],
      "metadata": {
        "id": "hXtdGiOgA66u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **6 (& 7). Training the model using Default Parameters, testing it and reporting the accuracy of the model**\n",
        "\n",
        "\n",
        "To simplify our task, we will be using cross_val_score and cross_val_predict from the sklearn library to train, test and evaluate our models using the split in step 5.\n",
        "\n",
        "These two functions automatically split X and y into train and test sets and fits the model according to these splits."
      ],
      "metadata": {
        "id": "NDbMZtMUDtip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**"
      ],
      "metadata": {
        "id": "vEtiFzGuDBpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "logisticRegModel = LogisticRegression(max_iter=500) #multi_class='multinomial', solver='lbfgs',\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "logisticReg_predictions1 = cross_val_predict(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model for each cross-validation fold\n",
        "logisticRegScores = cross_val_score(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {logisticRegScores}\")\n",
        "print('Accuracy: %.3f' % mean(logisticRegScores))"
      ],
      "metadata": {
        "id": "-ScYkZmlmX9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a6d70a-4f0e-45f3-b820-9c6088fe7aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.56703911 0.48510242 0.66852886 0.63280522 0.56570363]\n",
            "Accuracy: 0.584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the result in the output above, we note that the third fold has the highest accuracy. This means that the training is most accurate when we use the third section as the testing and the rest for the training data.\n"
      ],
      "metadata": {
        "id": "hA94ssRBjZ06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes:**"
      ],
      "metadata": {
        "id": "S2bojW4-mJHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NB_model = GaussianNB()\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "NB_predictions1 = cross_val_predict(NB_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "NB_scores = cross_val_score(NB_model, X, y.values.ravel(), cv=5)\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {NB_scores}\")\n",
        "print('Accuracy: %.3f' % mean(NB_scores))"
      ],
      "metadata": {
        "id": "nm8F-1wgdQwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263bb20d-6d1e-4c07-ee0b-9faab0d01193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.51210428 0.52141527 0.68808194 0.7110904  0.57875116]\n",
            "Accuracy: 0.602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the result in the output above, we note that the fourth fold has the highest accuracy."
      ],
      "metadata": {
        "id": "LvJj2_jr05HT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Layer Perceptron:**"
      ],
      "metadata": {
        "id": "6tcte1Hymd6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_model = MLPClassifier(solver='adam', alpha=1e-5, random_state=1) #solver='sgd', alpha=1e-5,hidden_layer_sizes=(100,2),random_state=1\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "MLP_predictions1 = cross_val_predict(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "MLP_scores = cross_val_score(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {MLP_scores}\")\n",
        "print('Accuracy: %.3f' % mean(MLP_scores))"
      ],
      "metadata": {
        "id": "ylwBVLy9dOaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa11ce93-4b25-4e54-923b-a29c0bc9c4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.5018622  0.45251397 0.65642458 0.62348555 0.59273066]\n",
            "Accuracy: 0.565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the result in the output above, we note that the third fold has the highest accuracy. Therefore, we conclude that this fold is the best."
      ],
      "metadata": {
        "id": "Dv9FF-ou0-ps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **8. Performing an evaluation with precision/recall measures**\n",
        "\n",
        "We will evaluate our models performance making predictions of y in comparison to the actual values of y\n"
      ],
      "metadata": {
        "id": "ApLg-kz6npbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#labels = [0, 1]\n",
        "labels=np.unique(NB_predictions1)\n",
        "print(f\"The labels: {labels}. 0 means the show is not on Netflix. 1 means the show is on Netflix.\")\n",
        "\n",
        "#Precision recall for Naive Bayes\n",
        "NB_precision_recall = precision_recall_fscore_support(y, NB_predictions1, average=None, labels=np.unique(NB_predictions1))\n",
        "\n",
        "#Precision recall for Logistic Regression\n",
        "LR_precision_recall= precision_recall_fscore_support(y, logisticReg_predictions1, average=None, labels=np.unique(logisticReg_predictions1))\n",
        "\n",
        "#Precision/recall for Multi-Layer Perceptron\n",
        "MLP_precision_recall = precision_recall_fscore_support(y, MLP_predictions1, average=None, labels=np.unique(MLP_predictions1))\n",
        "\n",
        "print(f\"The precision for class 1 Naive Bayes is {NB_precision_recall[0][1]:.3f} and for class 0 is {NB_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Naive Bayes is {NB_precision_recall[1][1]:.3f} and for class 0 is {NB_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Logistic Regression is {LR_precision_recall[0][1]:.3f} and for class 0 is {LR_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Logistic Regression is {LR_precision_recall[1][1]:.3f} and for class 0 is {LR_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Multi-Perceptron is {MLP_precision_recall[0][1]:.3f} and for class 0 is {MLP_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Multi-Perceptron is {MLP_precision_recall[1][1]:.3f} and for class 0 is {MLP_precision_recall[1][0]:.3f}\")"
      ],
      "metadata": {
        "id": "WtuSRyJUnzOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf607605-fb2d-4a55-c835-3ff033ae9fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The labels: [0 1]. 0 means the show is not on Netflix. 1 means the show is on Netflix.\n",
            "The precision for class 1 Naive Bayes is 0.467 and for class 0 is 0.721\n",
            "The recall for class 1 Naive Bayes is 0.597 and for class 0 is 0.605\n",
            "The precision for class 1 Logistic Regression is 0.416 and for class 0 is 0.653\n",
            "The recall for class 1 Logistic Regression is 0.329 and for class 0 is 0.732\n",
            "The precision for class 1 Multi-Perceptron is 0.341 and for class 0 is 0.626\n",
            "The recall for class 1 Multi-Perceptron is 0.197 and for class 0 is 0.779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision evalutes how often the model is correct at predicting if a tv show is on Netflix or not. \n",
        "Recall evaluates how correctly the model idenfities all Netflix shows. \n",
        "\n",
        "For example, the precision for class 1 Naive Bayes is 0.467 which means the model is correct 46.7% of the time when it predicts a show is on Netflix. The recall for Naive Bayes is 0.597 which means the model identifies 59.7% of all Netflix shows.\n",
        "\n",
        "Based on the values given, the models performed better at predicting if a show was not on Netflix than if it was on Netflix. Also, Naive Bayes performed best at identifying a larger percent of Netflix shows."
      ],
      "metadata": {
        "id": "Ur7VgWtQNsSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Modifying parameters**\n",
        "\n"
      ],
      "metadata": {
        "id": "GB9TSHR4PrcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1st round of modifications**\n",
        "\n",
        "For the first round of modifications, we attempted to use different parameters to observe the change in the results"
      ],
      "metadata": {
        "id": "jUksFyggQ11j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**"
      ],
      "metadata": {
        "id": "2opVLBlc3GG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "logisticRegModel = LogisticRegression(solver='saga', warm_start = True, max_iter=6000) #default solver is lbfgs\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "logisticReg_predictions2 = cross_val_predict(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model for each cross-validation fold\n",
        "logisticRegScores = cross_val_score(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {logisticRegScores}\")\n",
        "print('Accuracy: %.3f' % mean(logisticRegScores))"
      ],
      "metadata": {
        "id": "9U6_J-VuQTHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78111e2-d495-4774-fd82-93563f38ea94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.56703911 0.48510242 0.66852886 0.63280522 0.56570363]\n",
            "Accuracy: 0.584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes:**"
      ],
      "metadata": {
        "id": "r1lJM2623RyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NB_model = GaussianNB(var_smoothing = 0.05) #default = 1e-09\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "NB_predictions2 = cross_val_predict(NB_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "NB_scores = cross_val_score(NB_model, X, y.values.ravel(), cv=5)\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {NB_scores}\")\n",
        "print('Accuracy: %.3f' % mean(NB_scores))"
      ],
      "metadata": {
        "id": "H94aCkfsQnxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2674f473-d1af-4cdb-e3b2-53dcbba1c10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.54562384 0.64711359 0.59404097 0.66728798 0.65144455]\n",
            "Accuracy: 0.621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Layer Perceptron:**"
      ],
      "metadata": {
        "id": "mmi341mp3V76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_model = MLPClassifier(solver='sgd', alpha=0.5,hidden_layer_sizes=(5,2),random_state=1,max_iter=6000) #default solver is adam\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "MLP_predictions2 = cross_val_predict(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "MLP_scores = cross_val_score(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {MLP_scores}\")\n",
        "print('Accuracy: %.3f' % mean(MLP_scores))"
      ],
      "metadata": {
        "id": "FGAReL8pQoEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be71512c-cc80-4b1b-f6d1-033c26d1479d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.61638734 0.52793296 0.66294227 0.5917987  0.63280522]\n",
            "Accuracy: 0.606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision and recall measures:**"
      ],
      "metadata": {
        "id": "0Dlaf3Ar3Ziy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[0, 1]\n",
        "print(f\"The labels for the predictions: {labels}. \\n0 means the show is not on Netflix. 1 means the show is on Netflix.\")\n",
        "\n",
        "\n",
        "#Precision recall for Naive Bayes\n",
        "NB_precision_recall = precision_recall_fscore_support(y, NB_predictions2, average=None, labels=[0,1])\n",
        "\n",
        "#Precision recall for Logistic Regression\n",
        "LR_precision_recall= precision_recall_fscore_support(y, logisticReg_predictions2, average=None, labels=[0,1])\n",
        "\n",
        "#Precision/recall for Multi-Layer Perceptron\n",
        "MLP_precision_recall = precision_recall_fscore_support(y, MLP_predictions2, average=None, labels=[0,1])\n",
        "\n",
        "print(f\"The precision for class 1 Naive Bayes is {NB_precision_recall[0][1]:.3f} and the class 0 is {NB_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Naive Bayes is {NB_precision_recall[1][1]:.3f} and for class 0 is {NB_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Logistic Regression is {LR_precision_recall[0][1]:.3f} and for class 0 is {LR_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Logistic Regression is {LR_precision_recall[1][1]:.3f} and for class 0 is {LR_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Multi-Perceptron is {MLP_precision_recall[0][1]:.3f} and for class 0 is {MLP_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Multi-Perceptron is {MLP_precision_recall[1][1]:.3f} and for class 0 is {MLP_precision_recall[1][0]:.3f}\")"
      ],
      "metadata": {
        "id": "2uJuByTaQ_Eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf696e29-0ca4-4e37-fdac-81a87af0dbfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The labels for the predictions: [0, 1]. \n",
            "0 means the show is not on Netflix. 1 means the show is on Netflix.\n",
            "The precision for class 1 Naive Bayes is 0.481 and the class 0 is 0.682\n",
            "The recall for class 1 Naive Bayes is 0.396 and for class 0 is 0.752\n",
            "The precision for class 1 Logistic Regression is 0.416 and for class 0 is 0.653\n",
            "The recall for class 1 Logistic Regression is 0.329 and for class 0 is 0.732\n",
            "The precision for class 1 Multi-Perceptron is 0.402 and for class 0 is 0.638\n",
            "The recall for class 1 Multi-Perceptron is 0.148 and for class 0 is 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**2nd round of modifications**\n",
        "\n",
        "For the second round of modifications, we used GridSearchCV to find the best parameters to observe the change in the results"
      ],
      "metadata": {
        "id": "qAq11PvlRHnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**"
      ],
      "metadata": {
        "id": "pb8FUKzz3l9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#figuring out the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
        "LG_classifier = LogisticRegression()\n",
        "params_LG = [\n",
        "    {'classifier' : [LogisticRegression()],\n",
        "     'classifier__penalty' : ['l2'],\n",
        "    'classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'classifier__solver' : ['sag']}\n",
        "]\n",
        "\n",
        "gs_LG = GridSearchCV(pipe,\n",
        "                     param_grid=params_LG, \n",
        "                     cv=5,\n",
        "                     verbose=1, \n",
        "                     scoring='accuracy')\n",
        "gs_LG.fit(X, y.values.ravel())\n",
        "print(f\"The best parameters are: {gs_LG.best_params_}\")\n",
        "\n",
        "# create model\n",
        "logisticRegModel = LogisticRegression(solver='sag', C=0.0001, warm_start = True, max_iter=6000) #default solver is lbfgs\n",
        "\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "logisticReg_predictions3 = cross_val_predict(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model for each cross-validation fold\n",
        "logisticRegScores = cross_val_score(logisticRegModel, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {logisticRegScores}\")\n",
        "print('Accuracy: %.3f' % mean(logisticRegScores))"
      ],
      "metadata": {
        "id": "4LhJSPGFRLXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f265813e-e6fb-45e4-affd-ab97284c7a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "The best parameters are: {'classifier': LogisticRegression(C=0.0001, solver='sag'), 'classifier__C': 0.0001, 'classifier__penalty': 'l2', 'classifier__solver': 'sag'}\n",
            "The scores of the 5 folds: [0.66573557 0.63314711 0.63314711 0.63280522 0.63280522]\n",
            "Accuracy: 0.640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes:**"
      ],
      "metadata": {
        "id": "ifqcCi4G3pvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "nb_classifier = GaussianNB()\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
        "                     param_grid=params_NB, \n",
        "                     cv=5,\n",
        "                     verbose=1, \n",
        "                     scoring='accuracy')\n",
        "gs_NB.fit(X, y.values.ravel())\n",
        "print(f\"The best parameters are: {gs_NB.best_params_}\")\n",
        "NB_model = GaussianNB(var_smoothing = 0.53366992312063) #default = 1e-09\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "NB_predictions3 = cross_val_predict(NB_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "NB_scores = cross_val_score(NB_model, X, y.values.ravel(), cv=5)\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {NB_scores}\")\n",
        "print('Accuracy: %.3f' % mean(NB_scores))\n"
      ],
      "metadata": {
        "id": "L7HZwigLRMMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498f21f0-9e98-413b-c274-6e6aa42c23db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "The best parameters are: {'var_smoothing': 0.533669923120631}\n",
            "The scores of the 5 folds: [0.65083799 0.63314711 0.63314711 0.63280522 0.63280522]\n",
            "Accuracy: 0.637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-Layer Perceptron:**"
      ],
      "metadata": {
        "id": "3wJcjTZw3rev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_model = MLPClassifier(solver='sgd', learning_rate = 'adaptive',alpha=0.05,hidden_layer_sizes=(4,1),random_state=1,max_iter=6000) #default solver='adam', alpha=1e-5\n",
        "#Generate cross-validated estimates for each input data point.\n",
        "MLP_predictions3 = cross_val_predict(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# Use score method to get accuracy of model\n",
        "MLP_scores = cross_val_score(MLP_model, X, y.values.ravel(), cv=5)\n",
        "\n",
        "# report performance\n",
        "print(f\"The scores of the 5 folds: {MLP_scores}\")\n",
        "print('Accuracy: %.3f' % mean(MLP_scores))"
      ],
      "metadata": {
        "id": "ORh2AqgGRL8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f5f440-fd47-44d8-e7a9-740538d996bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scores of the 5 folds: [0.61545624 0.59404097 0.63314711 0.64492078 0.5890028 ]\n",
            "Accuracy: 0.615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision and recall measures:**"
      ],
      "metadata": {
        "id": "y-dRiwPl3som"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [0, 1]\n",
        "#labels=np.unique(NB_predictions)\n",
        "print(f\"The labels for the predictions: {labels}. \\n0 means the show is not on Netflix. 1 means the show is on Netflix.\")\n",
        "\n",
        "#Precision recall for Naive Bayes\n",
        "NB_precision_recall = precision_recall_fscore_support(y, NB_predictions3, average=None, labels=labels)\n",
        "\n",
        "#Precision recall for Logistic Regression\n",
        "LR_precision_recall= precision_recall_fscore_support(y, logisticReg_predictions3, average=None, labels=labels)\n",
        "\n",
        "#Precision/recall for Multi-Layer Perceptron\n",
        "MLP_precision_recall = precision_recall_fscore_support(y, MLP_predictions3, average=None, labels=labels)\n",
        "\n",
        "print(f\"The precision for class 1 Naive Bayes is {NB_precision_recall[0][1]:.3f} and the class 0 is {NB_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Naive Bayes is {NB_precision_recall[1][1]:.3f} and for class 0 is {NB_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Logistic Regression is {LR_precision_recall[0][1]:.3f} and for class 0 is {LR_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Logistic Regression is {LR_precision_recall[1][1]:.3f} and for class 0 is {LR_precision_recall[1][0]:.3f}\")\n",
        "print(f\"The precision for class 1 Multi-Perceptron is {MLP_precision_recall[0][1]:.3f} and for class 0 is {MLP_precision_recall[0][0]:.3f}\")\n",
        "print(f\"The recall for class 1 Multi-Perceptron is {MLP_precision_recall[1][1]:.3f} and for class 0 is {MLP_precision_recall[1][0]:.3f}\")"
      ],
      "metadata": {
        "id": "7bM0NEe2RLvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e405cbf3-7f12-477f-bd6b-90009b162400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The labels for the predictions: [0, 1]. \n",
            "0 means the show is not on Netflix. 1 means the show is on Netflix.\n",
            "The precision for class 1 Naive Bayes is 0.530 and the class 0 is 0.644\n",
            "The recall for class 1 Naive Bayes is 0.090 and for class 0 is 0.954\n",
            "The precision for class 1 Logistic Regression is 0.561 and for class 0 is 0.644\n",
            "The recall for class 1 Logistic Regression is 0.084 and for class 0 is 0.962\n",
            "The precision for class 1 Multi-Perceptron is 0.354 and for class 0 is 0.632\n",
            "The recall for class 1 Multi-Perceptron is 0.058 and for class 0 is 0.939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "###**10. Analying the obtained results**\n",
        "\n",
        "**a. Quantitative comparison:**\n",
        "\n",
        "The first two overall accuracies for cross-validation in Logistic Regression are equal at a value of 0.584 whereas using GridSearchCV to find the best parameters in the last round of modification brings it up to 0.640. For this reason, it is expected that the precision and recall measures were identical for the first and second sets of parameters. With the last modification having the best accuracy, the model is correct 56.1% of the time for assuming if a given show is on Netflix and 64.4% for assuming if it is not. The lowest value of recall is for the class 1 in the last modification which indicates that the model identifies 8.4% of all Netflix shows. The highest is for class 0 in the last modification which indicates that the model identifies 96.2% of all shows that are not on Netflix.\n",
        "\n",
        "Using Naives Bayes, the accuracy gets higher progressively going from 0.602 to 0.637, also using the help of GridSearchCV. The precision for predicting if a show is on Netflix (1) goes up each round but goes down when predicting if it is not on Netflix (0). The opposite is true for the recall. The lowest precision value for class 0 is that the model is correct 64.4% of the time which is still better than the predictions for 1. The lowest value of recall is for the class 1 in the last modification which indicates that the model identifies 9% of all Netflix shows. The highest is for class 0 in the last modification which indicates that the model identifies 95.4% of all shows that are not on Netflix. These scores are similar to those of the Logistic Regression model.\n",
        "\n",
        "As described in two paragraphs above, we note that the results for Logistic Regression and Naives Bayes are very similar. Let's now analyze the results of the Multi-Layer Perceptron (MLP) model which differ more.\n",
        "\n",
        "In the modifcations for MLP, the cross-validation accuracies also get progressively higher going from 0.565 to 0.615. However, the best precision and recall measures are not at the last modification; they are in the first round of modification. The only value that gets higher as we modify the parameters is the recall for class 0 which goes up to 93.9%. The lowest recall for class 1 with those same parameters is equivalent to 5.8%: the lowest value of all the models. The highest precision for class 1 is the lowest of all the models at a value of 0.354.\n",
        "\n",
        "The preceding observations prove that the accuracy of the test values is in correlation with the recall and precision measures. These results would indicate that the Logistic Regression model is the best to use for this dataset whereas Multi-Layer Perceptron would be the worst to use, even though the values don't differ significantly. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IIYO3TEKRlbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**b. Observing good and bad results**"
      ],
      "metadata": {
        "id": "absbUcGbIthJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#(tn, fp, fn, tp)\n",
        "#Confusing matrix for Naive Bayes\n",
        "cmNB1 = confusion_matrix(y, NB_predictions1).ravel()\n",
        "cmNB2 = confusion_matrix(y, NB_predictions2).ravel()\n",
        "cmNB3 = confusion_matrix(y, NB_predictions2).ravel()\n",
        "\n",
        "#confusion matrix for Logistic Regression \n",
        "cmLG1 = confusion_matrix(y, logisticReg_predictions1).ravel()\n",
        "cmLG2 = confusion_matrix(y, logisticReg_predictions2).ravel()\n",
        "cmLG3 = confusion_matrix(y, logisticReg_predictions3).ravel()\n",
        "\n",
        "#Confusing matrix for MLP \n",
        "cmMLP1 = confusion_matrix(y, MLP_predictions1).ravel()\n",
        "cmMLP2 = confusion_matrix(y, MLP_predictions1).ravel()\n",
        "cmMLP3 = confusion_matrix(y, MLP_predictions1).ravel()\n",
        "\n",
        "print(f\"For Naive Bayes 1: (tn, fp, fn, tp) = {cmNB1}\")\n",
        "print(f\"For Naive Bayes 2: (tn, fp, fn, tp) = {cmNB2}\")\n",
        "print(f\"For Naive Bayes 3: (tn, fp, fn, tp) = {cmNB3}\")\n",
        "\n",
        "print(f\"For Logistic Regression 1: (tn, fp, fn, tp) = {cmLG1}\")\n",
        "print(f\"For Logistic Regression 2: (tn, fp, fn, tp) = {cmLG2}\")\n",
        "print(f\"For Logistic Regression 3: (tn, fp, fn, tp) = {cmLG3}\")\n",
        "\n",
        "print(f\"For Multi-Layer Perceptron 1: (tn, fp, fn, tp) = {cmMLP1}\")\n",
        "print(f\"For Multi-Layer Perceptron 2: (tn, fp, fn, tp) = {cmMLP2}\")\n",
        "print(f\"For Multi-Layer Perceptron 3: (tn, fp, fn, tp) = {cmMLP3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmNNlFEXguZR",
        "outputId": "80e09e06-c5c5-4c3e-f4df-8fb3913ac7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Naive Bayes 1: (tn, fp, fn, tp) = [2056 1341  794 1177]\n",
            "For Naive Bayes 2: (tn, fp, fn, tp) = [2554  843 1191  780]\n",
            "For Naive Bayes 3: (tn, fp, fn, tp) = [2554  843 1191  780]\n",
            "For Logistic Regression 1: (tn, fp, fn, tp) = [2486  911 1323  648]\n",
            "For Logistic Regression 2: (tn, fp, fn, tp) = [2486  911 1323  648]\n",
            "For Logistic Regression 3: (tn, fp, fn, tp) = [3267  130 1805  166]\n",
            "For Multi-Layer Perceptron 1: (tn, fp, fn, tp) = [2647  750 1583  388]\n",
            "For Multi-Layer Perceptron 2: (tn, fp, fn, tp) = [2647  750 1583  388]\n",
            "For Multi-Layer Perceptron 3: (tn, fp, fn, tp) = [2647  750 1583  388]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 1"
      ],
      "metadata": {
        "id": "YX6ymtg95pBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*`Here Naive Bayes 1 refers to the original round. While Naive Bayes 2 and 3 refer to modification rounds 1 and 2 and the same applies to all models.`*\n",
        "\n",
        "We can see from the results above that MLP had consisent true negatives, false positives, false negatives and true positives across all 3 results.\n",
        "\n",
        "Naive Bayes had the most difference between its values for false positive, false negative and true positive across the 3 rounds. \n",
        "\n",
        "Since Naive Bayes 1 has the highest amount of true positives and second highest true negatives, it has the highest amount of good results. We wll use Naive Bayes 1 predictions going forward to compare results"
      ],
      "metadata": {
        "id": "Sa9n3xJwl0uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.values.ravel())\n",
        "print(NB_predictions1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73DRoZpbmQyy",
        "outputId": "73c8b0d9-7339-42fa-ee6c-8262fe265b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "[0 1 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jnCtOhJMnw-d",
        "outputId": "e339b3b5-fb3d-41ed-a648-a62fb7c25b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Title  Year   Age  IMDb  Rotten Tomatoes  Netflix  Hulu  \\\n",
              "0      Breaking Bad     4  18.0     4                3        1     0   \n",
              "1   Stranger Things     5  16.0     4                3        1     0   \n",
              "2   Attack on Titan     5  18.0     4                3        1     1   \n",
              "3  Better Call Saul     5  18.0     4                3        1     0   \n",
              "4              Dark     5  16.0     4                3        1     0   \n",
              "\n",
              "   Prime Video  Disney+  \n",
              "0            0        0  \n",
              "1            0        0  \n",
              "2            0        0  \n",
              "3            0        0  \n",
              "4            0        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c63722b7-d587-4b03-a31c-40a14fe696de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Age</th>\n",
              "      <th>IMDb</th>\n",
              "      <th>Rotten Tomatoes</th>\n",
              "      <th>Netflix</th>\n",
              "      <th>Hulu</th>\n",
              "      <th>Prime Video</th>\n",
              "      <th>Disney+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Breaking Bad</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stranger Things</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Attack on Titan</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Better Call Saul</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dark</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c63722b7-d587-4b03-a31c-40a14fe696de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c63722b7-d587-4b03-a31c-40a14fe696de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c63722b7-d587-4b03-a31c-40a14fe696de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table 2"
      ],
      "metadata": {
        "id": "UY4Sl2qQ5s4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Year category for Year 4.\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 4) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 4) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(f\"Year 4 & Age Demographic 16\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 4) & (dataset['Age'] == 16.0) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 4)& (dataset['Age'] == 16.0) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(f\"Year 4 & Age Demographic 18\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 4) & (dataset['Age'] == 18.0) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 4)& (dataset['Age'] == 18.0) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(\"Year category for Year 5.\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 5) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 5) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(f\"Year 5 & Age Demographic 16\")\n",
        "print(f\"On Netflix   {len(dataset.loc[(dataset['Year'] == 5) & (dataset['Age'] == 16.0) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 5)& (dataset['Age'] == 16.0) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(f\"Year 5 & Age Demographic 18\")\n",
        "print(f\"On Netflix {len(dataset.loc[(dataset['Year'] == 5) & (dataset['Age'] == 18.0) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 5)& (dataset['Age'] == 18.0) & (dataset['Netflix'] == 0)])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgqBRiWjon5T",
        "outputId": "a91f1e15-7156-4fe4-b556-4f0cce3e8d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Year category for Year 4.\n",
            "On Netflix  50\n",
            "Not on Netflix 269\n",
            "Year 4 & Age Demographic 16\n",
            "On Netflix  15\n",
            "Not on Netflix 59\n",
            "Year 4 & Age Demographic 18\n",
            "On Netflix  4\n",
            "Not on Netflix 39\n",
            "Year category for Year 5.\n",
            "On Netflix  1844\n",
            "Not on Netflix 2562\n",
            "Year 5 & Age Demographic 16\n",
            "On Netflix   353\n",
            "Not on Netflix 461\n",
            "Year 5 & Age Demographic 18\n",
            "On Netflix 473\n",
            "Not on Netflix 298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, we can see the Naive Bayes prediction for Breaking Bad is a false negative.\n",
        "\n",
        "Based on the numbers above, this is probably due to the difference in the Year (category) that the show came out. Most shows in the Year 4 category are not on Netflix.\n",
        "\n",
        "\n",
        "Whereas, for Stranger Things and Attack on Titans, it is a true positive. And this is despite the fact that Stranger things is for a different age demographic. Most likely because other features pointed towards the show being on Netflix. For example, despite the fact that most shows in the year 5 are not on Netflix, year 5 still has a much higher rate of shows on Netflix than year 4\n",
        "\n",
        "Below, we can search for false positives\n",
        "\n"
      ],
      "metadata": {
        "id": "38lUSAEfndes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "false_positives = []\n",
        "for val in y.values.ravel():\n",
        "  if val == 0 and NB_predictions1[i] == 1: #predicted 1 but the actual value is 0 means its a false positive\n",
        "    false_positives.append(i)\n",
        "  i = i+1\n",
        "\n",
        "print(false_positives)\n",
        "\n",
        "print(f\"Row 1951 is a true negative  {y.values.ravel()[1951]} and {NB_predictions1[1951]} also shown below\")\n"
      ],
      "metadata": {
        "id": "oN39k_lssrTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec0d108-fdc9-4500-b79a-0fdb7a46e5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1950, 1952, 1953, 1954, 1956, 1960, 1963, 1965, 1970, 1971, 1972, 1976, 1977, 1978, 1984, 1986, 1988, 1989, 1992, 1993, 1995, 1997, 1998, 1999, 2001, 2002, 2005, 2008, 2012, 2013, 2016, 2017, 2018, 2019, 2020, 2021, 2023, 2024, 2025, 2027, 2028, 2031, 2033, 2035, 2036, 2037, 2038, 2039, 2042, 2043, 2045, 2046, 2047, 2048, 2049, 2051, 2053, 2055, 2056, 2057, 2058, 2060, 2061, 2062, 2063, 2065, 2066, 2067, 2068, 2070, 2071, 2072, 2075, 2076, 2077, 2078, 2080, 2081, 2083, 2085, 2087, 2088, 2089, 2090, 2091, 2092, 2094, 2095, 2098, 2099, 2100, 2104, 2106, 2108, 2109, 2110, 2111, 2112, 2113, 2116, 2117, 2119, 2121, 2125, 2126, 2128, 2129, 2130, 2131, 2133, 2134, 2136, 2137, 2138, 2139, 2140, 2142, 2143, 2144, 2145, 2147, 2148, 2150, 2153, 2154, 2155, 2158, 2159, 2161, 2162, 2163, 2164, 2169, 2170, 2171, 2173, 2174, 2175, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2191, 2192, 2193, 2197, 2199, 2200, 2202, 2203, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2215, 2216, 2217, 2219, 2220, 2222, 2223, 2224, 2226, 2227, 2229, 2230, 2233, 2234, 2236, 2239, 2240, 2241, 2244, 2245, 2246, 2248, 2249, 2251, 2252, 2255, 2256, 2257, 2259, 2260, 2261, 2263, 2264, 2266, 2267, 2269, 2272, 2273, 2274, 2275, 2276, 2277, 2279, 2280, 2282, 2283, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2298, 2300, 2301, 2302, 2303, 2304, 2308, 2309, 2311, 2312, 2314, 2315, 2316, 2317, 2318, 2319, 2321, 2324, 2325, 2326, 2327, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2341, 2342, 2343, 2347, 2348, 2353, 2354, 2355, 2356, 2358, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2369, 2370, 2371, 2372, 2374, 2375, 2376, 2377, 2378, 2379, 2382, 2383, 2384, 2387, 2388, 2390, 2392, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2408, 2412, 2413, 2414, 2415, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2427, 2428, 2429, 2430, 2432, 2433, 2434, 2435, 2436, 2437, 2440, 2441, 2443, 2444, 2448, 2449, 2452, 2454, 2457, 2459, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2470, 2475, 2476, 2477, 2479, 2480, 2481, 2482, 2484, 2486, 2488, 2489, 2490, 2491, 2492, 2493, 2495, 2496, 2499, 2500, 2501, 2502, 2504, 2505, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2535, 2537, 2538, 2540, 2542, 2543, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2557, 2559, 2560, 2562, 2563, 2564, 2566, 2567, 2568, 2569, 2570, 2572, 2574, 2576, 2577, 2578, 2579, 2580, 2582, 2585, 2586, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2598, 2599, 2600, 2601, 2603, 2604, 2605, 2606, 2607, 2609, 2610, 2611, 2613, 2614, 2616, 2617, 2619, 2621, 2622, 2623, 2624, 2627, 2628, 2629, 2630, 2632, 2634, 2635, 2636, 2637, 2640, 2641, 2642, 2643, 2644, 2647, 2648, 2650, 2652, 2653, 2655, 2656, 2657, 2658, 2660, 2661, 2662, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2673, 2674, 2675, 2676, 2677, 2678, 2680, 2681, 2682, 2683, 2684, 2686, 2687, 2688, 2689, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2712, 2713, 2714, 2715, 2717, 2718, 2720, 2721, 2722, 2723, 2724, 2725, 2727, 2728, 2731, 2732, 2733, 2734, 2735, 2736, 2739, 2740, 2741, 2742, 2744, 2745, 2747, 2748, 2749, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2766, 2767, 2768, 2770, 2773, 2774, 2776, 2777, 2778, 2779, 2781, 2782, 2783, 2785, 2787, 2788, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2815, 2816, 2817, 2819, 2820, 2821, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2840, 2841, 2842, 2844, 2845, 2846, 2849, 2850, 2851, 2853, 2854, 2856, 2858, 2860, 2864, 2866, 2869, 2871, 2872, 2873, 2874, 2876, 2879, 2880, 2881, 2882, 2886, 2887, 2888, 2889, 2891, 2892, 2893, 2894, 2895, 2896, 2898, 2899, 2900, 2901, 2902, 2904, 2906, 2907, 2908, 2909, 2910, 2913, 2914, 2915, 2916, 2917, 2918, 2920, 2921, 2923, 2925, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2939, 2940, 2941, 2942, 2943, 2944, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2969, 2970, 2971, 2975, 2977, 2978, 2979, 2981, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2991, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3003, 3004, 3005, 3006, 3008, 3009, 3010, 3011, 3012, 3015, 3017, 3020, 3021, 3022, 3024, 3025, 3026, 3027, 3028, 3032, 3034, 3035, 3036, 3037, 3039, 3040, 3042, 3043, 3046, 3047, 3048, 3049, 3050, 3052, 3053, 3054, 3055, 3056, 3057, 3059, 3060, 3061, 3062, 3063, 3069, 3070, 3071, 3072, 3073, 3075, 3077, 3078, 3079, 3081, 3082, 3083, 3084, 3085, 3088, 3089, 3091, 3092, 3094, 3095, 3096, 3098, 3099, 3100, 3103, 3104, 3105, 3107, 3108, 3109, 3110, 3111, 3112, 3114, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3128, 3129, 3130, 3132, 3133, 3134, 3135, 3136, 3138, 3139, 3140, 3141, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3160, 3161, 3162, 3163, 3165, 3166, 3167, 3170, 3171, 3172, 3174, 3178, 3179, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3196, 3197, 3199, 3200, 3201, 3202, 3205, 3206, 3208, 3209, 3210, 3211, 3214, 3215, 3216, 3218, 3219, 3221, 3222, 3224, 3226, 3228, 3229, 3230, 3232, 3235, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3249, 3257, 3261, 3262, 3265, 3275, 3279, 3284, 3446, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3458, 3459, 3460, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3472, 3475, 3476, 3477, 3478, 3480, 3481, 3486, 3487, 3488, 3489, 3490, 3491, 3493, 3494, 3495, 3496, 3500, 3501, 3502, 3503, 3505, 3506, 3507, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3529, 3532, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3544, 3545, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3560, 3561, 3564, 3566, 3567, 3573, 3574, 3575, 3577, 3579, 3580, 3583, 3584, 3585, 3588, 3589, 3590, 3591, 3592, 3594, 3595, 3600, 3602, 3603, 3605, 3606, 3608, 3609, 3610, 3613, 3614, 3618, 3619, 3621, 3622, 3624, 3625, 3626, 3627, 3628, 3629, 3631, 3632, 3633, 3634, 3636, 3637, 3638, 3640, 3642, 3643, 3645, 3646, 3648, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3660, 3661, 3665, 3667, 3668, 3670, 3671, 3673, 3675, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3692, 3693, 3696, 3697, 3698, 3699, 3700, 3702, 3706, 3707, 3708, 3711, 3714, 3716, 3718, 3719, 3722, 3724, 3727, 3728, 3729, 3733, 3737, 3738, 3740, 3742, 3743, 3746, 3747, 3748, 3749, 3750, 3752, 3754, 3756, 3757, 3758, 3760, 3761, 3763, 3766, 3768, 3770, 3771, 3772, 3773, 3774, 3776, 3777, 3781, 3782, 3784, 3786, 3787, 3791, 3792, 3794, 3796, 3797, 3798, 3800, 3801, 3802, 3804, 3806, 3807, 3808, 3811, 3812, 3813, 3817, 3818, 3820, 3822, 3823, 3824, 3826, 3827, 3828, 3829, 3831, 3833, 3836, 3838, 3840, 3842, 3843, 3845, 3849, 3851, 3852, 3853, 3868, 3870, 3872, 3874, 3875, 3876, 3879, 3882, 3884, 3894, 3896, 3897, 3904, 3905, 3907, 3915, 3920, 3923, 3925, 3935, 3942, 3944, 3949, 3952, 3969, 3981, 3984, 3986, 3994, 3995, 4002, 4008, 4030, 4036, 4038, 4046, 4049, 4060, 4061, 4067, 4069, 4072, 4079, 4101, 4109, 4121, 4129, 4140, 4150, 4179, 4180, 4195, 4203, 4229, 4232, 4237, 4249, 4268, 4272, 4280, 4283, 4287, 4321, 4327, 4331, 4333, 4359, 4366, 4370, 4380, 4382, 5057, 5058, 5059, 5060, 5062, 5063, 5065, 5066, 5068, 5069, 5070, 5071, 5074, 5075, 5077, 5079, 5083, 5084, 5086, 5087, 5088, 5089, 5090, 5091, 5092, 5096, 5098, 5099, 5100, 5104, 5106, 5109, 5110, 5111, 5113, 5115, 5119, 5120, 5121, 5122, 5123, 5124, 5127, 5129, 5130, 5131, 5135, 5136, 5140, 5142, 5143, 5146, 5147, 5148, 5149, 5154, 5155, 5156, 5157, 5158, 5159, 5160, 5161, 5162, 5164, 5165, 5166, 5167, 5168, 5170, 5171, 5173, 5174, 5175, 5176, 5177, 5179, 5180, 5181, 5182, 5183, 5184, 5185, 5186, 5187, 5189, 5190, 5191, 5193, 5194, 5195, 5196, 5199, 5200, 5201, 5202, 5203, 5265]\n",
            "Row 1951 is a true negative  0 and 0 also shown below\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that row 1950, 1952, 1953 and 1954 are false positives. "
      ],
      "metadata": {
        "id": "iwBXBDGg_Orw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.loc[(dataset['Netflix'] == 0)].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wq8FQcNxse1S",
        "outputId": "6e6aa0ac-78d4-4f5a-bcd5-268d04d6bac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Title  Year   Age  IMDb  Rotten Tomatoes  Netflix  Hulu  \\\n",
              "1950      Rick and Morty     5  18.0     4                3        0     1   \n",
              "1951            Seinfeld     2  16.0     4                3        0     1   \n",
              "1952             Vikings     5  18.0     4                3        0     1   \n",
              "1953               Fargo     5  18.0     4                3        0     1   \n",
              "1954  Brooklyn Nine-Nine     5  16.0     4                3        0     1   \n",
              "\n",
              "      Prime Video  Disney+  \n",
              "1950            0        0  \n",
              "1951            0        0  \n",
              "1952            1        0  \n",
              "1953            0        0  \n",
              "1954            0        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12ed90bd-55ab-4d83-9462-c5c71165c8f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Age</th>\n",
              "      <th>IMDb</th>\n",
              "      <th>Rotten Tomatoes</th>\n",
              "      <th>Netflix</th>\n",
              "      <th>Hulu</th>\n",
              "      <th>Prime Video</th>\n",
              "      <th>Disney+</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>Rick and Morty</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>Seinfeld</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>Vikings</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>Fargo</td>\n",
              "      <td>5</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>Brooklyn Nine-Nine</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12ed90bd-55ab-4d83-9462-c5c71165c8f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12ed90bd-55ab-4d83-9462-c5c71165c8f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12ed90bd-55ab-4d83-9462-c5c71165c8f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table 3"
      ],
      "metadata": {
        "id": "dAMuWl3i5zvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Row 1954: Year Demographic for Year 5, IMDb 4 and Age 16.\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 5) & (dataset['IMDb'] == 4) & (dataset['Age'] == 16) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 5) & (dataset['IMDb'] == 4)& (dataset['Age'] == 16.0) & (dataset['Netflix'] == 0)])}\")\n",
        "\n",
        "print(\"Row 1951: Year Demographic for Year 2 , IMDb 4 and Age 16.\")\n",
        "print(f\"On Netflix  {len(dataset.loc[(dataset['Year'] == 2) & (dataset['IMDb'] == 4) & (dataset['Age'] == 16) & (dataset['Netflix'] == 1)])}\")\n",
        "print(f\"Not on Netflix {len(dataset.loc[(dataset['Year'] == 2) & (dataset['IMDb'] == 4) & (dataset['Age'] == 16) & (dataset['Netflix'] == 0)])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyw430Gr_-_2",
        "outputId": "c423d4c3-06c6-4e47-ed46-b620e59bd790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 1954: Year Demographic for Year 5, IMDb 4 and Age 16.\n",
            "On Netflix  102\n",
            "Not on Netflix 87\n",
            "Row 1951: Year Demographic for Year 2 , IMDb 4 and Age 16.\n",
            "On Netflix  2\n",
            "Not on Netflix 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing row 1954 (Brooklyn 99) and row 1951 (Seinfeld) provides some insight into the false positives. \n",
        "\n",
        "Other rows with same values as row 1951 are mostly not on Netflix as predicted.\n",
        "\n",
        "But Row 1954 which has similar values as row 1951 except that it is a a Year 5 intead of Year 2. And as shown before, Year 5 has a high rate of shows on Netflix. And shows with the same values as row 1954 are more likely to be on Netflix than not. Which is probably why it was a false positive."
      ],
      "metadata": {
        "id": "EeaQjs6pseMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice in figure 1 that the values for Logistic Regression and Naive Bayes are very similar, as they were in *section a* when we compared the recall and precision measures. Let's consider the sum of true positive and true negative results in the last modification. For Logistic Regression, the number of sets guessed correctly is 3433. For Naive Bayes, it is 3334. The difference of 99 is not large enough to say that one model is significantly better than the other. The numbers are close enough that the model considered the \"best\" might change depending on the sets we use for testing. However, since the measures observed in *section a* lead to the conclusion that Logistic Regression is better, we conclude that using this model is the best option for the dataset studied, with the parameters of the last modification.\n",
        "\n"
      ],
      "metadata": {
        "id": "XWC68i184ZJ8"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
